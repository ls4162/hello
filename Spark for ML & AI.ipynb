{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('spark ml').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Organizing data in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_dir = '/Users/leis/Lynda/Spark for ML & AI/Ex_Files_Spark_ML_AI/Exercise Files'\n",
    "src_file = 'Ch01/01_04/employee.txt'\n",
    "\n",
    "\n",
    "src_path = os.path.join(base_dir, src_file)\n",
    "emp_df = spark.read.csv(src_path, header=True)\n",
    "# emp_df\n",
    "# emp_df.schema\n",
    "# emp_df.printSchema\n",
    "# emp_df.columns\n",
    "# emp_df.take(5)\n",
    "# emp_df.count()\n",
    "# sample_df = emp_df.sample(False, 0.1) #without replacement\n",
    "# sample_df.count()\n",
    "# emp_mgrs_df = emp_df.filter('salary >= 100000')\n",
    "# emp_mgrs_df.count()\n",
    "# emp_mgrs_df.select('salary').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Normalize numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|          features|           sfeatures|\n",
      "+------------------+--------------------+\n",
      "|[10.0,10000.0,1.0]|       [0.0,0.0,0.0]|\n",
      "|[20.0,30000.0,2.0]|[0.5,0.6666666666...|\n",
      "|[30.0,40000.0,3.0]|       [1.0,1.0,1.0]|\n",
      "+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "features_df = spark.createDataFrame(\n",
    "                                 [(1, Vectors.dense([10.0, 10000.0, 1.0]),),\n",
    "                                  (2, Vectors.dense([20.0, 30000.0, 2.0]),),\n",
    "                                  (3, Vectors.dense([30.0, 40000.0, 3.0]),)],\n",
    "                                 ['id', 'features']\n",
    "                                 )\n",
    "features_df.take(1)\n",
    "feature_scaler = MinMaxScaler(inputCol='features', outputCol='sfeatures')\n",
    "smodel = feature_scaler.fit(features_df)\n",
    "sfeatures_df = smodel.transform(features_df)\n",
    "sfeatures_df.take(1)\n",
    "sfeatures_df.select(\"features\", \"sfeatures\").show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Stardardize numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+--------------------+\n",
      "| id|          features|           sfeatures|\n",
      "+---+------------------+--------------------+\n",
      "|  1|[10.0,10000.0,1.0]|[-1.0,-1.09108945...|\n",
      "|  2|[20.0,30000.0,2.0]|[0.0,0.2182178902...|\n",
      "|  3|[30.0,40000.0,3.0]|[1.0,0.8728715609...|\n",
      "+---+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "features_df = spark.createDataFrame(\n",
    "                                    [(1, Vectors.dense([10.0, 10000.00, 1.0]),),\n",
    "                                     (2, Vectors.dense([20.0, 30000.00, 2.0]),),\n",
    "                                     (3, Vectors.dense([30.0, 40000.00, 3.0]),)\n",
    "                                    ],\n",
    "                                    ['id', 'features']\n",
    "                                    )\n",
    "features_df.take(1)\n",
    "feature_stand_scaler = StandardScaler(inputCol='features', \n",
    "                                      outputCol='sfeatures',\n",
    "                                      withStd = True,\n",
    "                                      withMean = True\n",
    "                                      )\n",
    "stand_smodel = feature_stand_scaler.fit(features_df)\n",
    "stand_sfeatures_df = stand_smodel.transform(features_df)\n",
    "stand_sfeatures_df.take(1)\n",
    "stand_sfeatures_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Bucketize numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|features|\n",
      "+--------+\n",
      "|  -800.0|\n",
      "|   -10.5|\n",
      "|    -1.7|\n",
      "|     0.0|\n",
      "|     8.2|\n",
      "|    90.1|\n",
      "+--------+\n",
      "\n",
      "+--------+---------+\n",
      "|features|bfeatures|\n",
      "+--------+---------+\n",
      "|  -800.0|      0.0|\n",
      "|   -10.5|      0.0|\n",
      "|    -1.7|      1.0|\n",
      "|     0.0|      2.0|\n",
      "|     8.2|      2.0|\n",
      "|    90.1|      3.0|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "splits = [-float('inf'), -10.0, 0.0, 10.0, float('inf')]\n",
    "b_data = [(-800.0,), (-10.5,), (-1.7,), (0.0,), (8.2,), (90.1,)]\n",
    "b_df = spark.createDataFrame(b_data, ['features'])\n",
    "b_df.show()\n",
    "bucketizer = Bucketizer(splits=splits, inputCol='features', outputCol='bfeatures')\n",
    "bucketed_df = bucketizer.transform(b_df)\n",
    "bucketed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
